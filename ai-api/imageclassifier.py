# -*- coding: utf-8 -*-
"""ImageClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M131z1mVljrJ59qJr__2aja9pl-L5m0a

첫 작성일 : 2025. 4. 9

첫 날 기록 : 필요 라이브러리 / 데이터 로드 / 증강(resize하여 crop)한 데이터와 원본 데이터 한 디렉토리에 합쳐 train, test split / pre-trained 모델 load 아래 설명 참고

모델
- EfficientNet_b3
- CrossEntropy()
- Adam optimizer(learning rate = 1e-4)
- epoch 5
- train loss, train accuracy, test accuracy, classification_report
- classifier 제거 후 embedding 추출

시각화
- train loss
- train accuracy, test accuracy
- t-SNE
- UMAP

다음에 할 일
- 교차검증
- confusion matrix 시각화

## 필요 라이브러리
"""

!pip install timm

import timm
import torch
import torch.nn as nn
# import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
import os
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report
from sklearn.manifold import TSNE
import umap.umap_ as umap
import torch.nn.functional as F
import shutil
from glob import glob

# 증강 데이터 저장 시
# from torchvision.utils import save_image
# import torchvision.transforms.functional as TF
# from PIL import Image

"""## 데이터 로드 및 증강"""

# !gdown https://drive.google.com/file/d/13Wc06NUYMvfUI3EJajo3N6h-LB8NYZa7/view?usp=drive_link -O ./train.csv
# !gdown https://drive.google.com/file/d/1Jx9TpHVnewFChIRF9S9zi3RWZkhNtvb0/view?usp=drive_link -O ./test.csv

!gdown https://drive.google.com/drive/folders/11JgRpOoSMraukeNH1Gah_R5CP3-qumkI?usp=drive_link -0

# 데이터 로드
data_dir = '/content/drive/MyDrive/your_dataset_folder'  # 경로에 맞게 수정해줘

# 데이터 증강
transform = transforms.Compose([
    transforms.RandomResizedCrop(300, scale=(0.8, 1.0), ratio=(0.95, 1.05)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# 작동 방법 : transforms는 이미지 로드 시마다 랜덤하게 augment하여 즉석으로 변형된 이미지 생성
# 원본 이미지만 유지되고, 매번 다르게 augment 되어 학습에 사용(저장되지 않음)
# 학습이 여러 epoch일 경우, 매 epoch마다 augmentation 방식이 바뀜
# 변형 이미지를 명시적으로 저장하지 않으면 메모리상에서만 존재

# 시각화 함수
def imshow_tensor(img_tensor):
    img = img_tensor.numpy().transpose((1, 2, 0))  # C x H x W → H x W x C

    # 사전 학습된 모델과 입력 분포를 맞추고, gradient 계산이 안정되고, 각 채널의 스케일을 균일화하기 위해
    # ImageNet 기준 평균과 표준편차를 사용
    mean = np.array([0.485, 0.456, 0.406])
    std  = np.array([0.229, 0.224, 0.225])
    img = std * img + mean  # De-normalize
    img = np.clip(img, 0, 1)
    plt.imshow(img)

# 증강 데이터 저장
aug_data = '/content/drive/MyDrive/augmented_dataset'
os.makedirs(aug_data, exist_ok = True)

# 이미지 폴더 경로
data_dir = '/content/drive/MyDrive/your_dataset_folder'  # 실제 경로로 바꿔줘
dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# DataLoader 로 순회하면서 저장
dataloader = DataLoader(dataset, batch_size=1, shuffle=False) # 증강 데이터 저장 안하면 batch size = 8, shuffle = True

for idx, (img, label) in enumerate(dataloader):
  class_name = dataset.classes[label.item()]
  class_dir = os.path.join(aug_data, class_name)
  os.makedirs(class_dir, exist_ok = True)

  # De-normalize 후 저장
  img_denorm = img.clone().squeeze(0)
  img_denorm = img_denorm*torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)
  img_denorm = img_denorm+torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
  img_denorm = torch.clamp(img_denorm, 0, 1)

  img_pil = TF.to_pil_image(img_denorm)
  # 이미지 데이터 크기를 줄이기 위해 png가 아닌 jpg로 저장되게 바꿈

  # 파일 이름 지정
  filename = f"{class_name}_{idx:04d}.jpg"
  save_path = os.path.join(class_dir, filename)
  img_pil.save(save_path, format = 'JPEG', quality = 85)

  if idx % 100 == 0:
    print(f"{idx}장 저장 완료...")

print("모든 증강 이미지 저장 완료")

# 이미지 시각화
data_iter = iter(dataloader)
images, labels = next(data_iter)

plt.figure(figsize=(15, 8))
for i in range(8):
    plt.subplot(2, 4, i+1)
    imshow_tensor(images[i])
    plt.title(f'Label: {dataset.classes[labels[i]]}')
    plt.axis('off')
plt.tight_layout()
plt.show()

# 원본 이미지 복사
for class_name in os.listdir(original_data_path):
  class_input_dir = os.path.join(original_data_path, class_name)
  class_output_dir = os.path.join(augmented_save_path, class_name)
  os.makedirs(class_output_dir, exist_ok=True)

  image_files = glob(os.path.join(class_input_dir, "*"))
  for img_path in image_files:
    filename = os.path.basename(img_path)
    dst_path = os.path.join(class_output_dir, f"orig_{filename}")
    shutil.copy(img_path, dst_path)

# 전처리 (normalize)
n_transform = transforms.Compose([
    transforms=transforms.Resize((300,300)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456,0.406],
                         [0.229, 0.224, 0.225])
    ])

data_d = datasets.ImageFolder(root=aug_data, transform = n_transform)
class_names = data_d.classes

# data split
train_size = int(0.8 * len(data_d))
test_size = len(data_d) - train_size
train_dataset, test_dataset = random_split(data_d, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)

"""## EfficientNet 모델 로딩 & 임베딩 추출"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# EfficientNet 모델 Load
eff_model = timm.create_model('efficientnet_b3', pretrained=True, num_classes = len(class_names))
eff_model = eff_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(eff_model.parameters(), lr = 1e-4)

train_losses = []
train_accuracies = []
test_accuracies = []

epochs = 5
for epoch in range(epochs):
  eff_model.train()
  running_loss = 0,0
  correct = 0
  total = 0

  for imgs, labels in train_loader:
    imgs, labels = imgs.to(device), labels.to(device)
    optimizer.zero_grad()
    outputs = eff_model(imgs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    running_loss += loss.item() * imgs.size(0)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

  epoch_loss = running_loss / total
  epoch_acc = correct / total
  train_losses.append(epoch_loss)
  train_accuracies.append(epoch_acc)

  print(f"Epoch {epoch+1} 완료")

  eff_model.eval()
  all_preds = []
  all_targets = []

  with torch.no_grad():
    for imgs, labels in test_loader:
      imgs = imgs.to(device)
      outputs = eff_model(imgs)
      preds = outputs.argmax(dim=1).cpu()
      all_preds.extend(preds.numpy())
      all_targets.extend(labels.numpy())

print("정확도 : ", accuracy_score(all_targets, all_preds))
print(classification_report(all_targets, all_preds, target_names = class_names))

eff_model.eval()

# 마지막 classifier 제거(임베딩만 추출)
feature_extractor = nn.Sequential(*list(eff_model.children())[:-1])
feature_extractor = feature_extractor.to(device)

all_embeddings = []
all_labels = []

with torch.no_grad():
  for imgs, labels in DataLoader(data_d, batch_size = 32):
    imgs = imgs.to(device)
    feats = feature_extractor(imgs)  # (batch, 1536, 1, 1)
    feats = feats.squeeze(-1).squeeze(-1)  # (batch, 1536)
    all_embeddings.append(feats.cpu())
    all_labels.append(labels)

# numpy 배열로 변환
embeddings = torch.cat(all_embeddings).numpy()  # (N, 1536)
labels = torch.cat(all_labels).numpy()  # (N,)

# save
np.save('/content/drive/MyDrive/image_embeddings.npy', embeddings)
np.save('/content/drive/MyDrive/image_labels.npy', labels)
print("임베딩과 라벨 저장 완료")

"""### 모델 시각화"""

# train loss
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_losses, label = "Train Loss", marker = 'o')
plt.title("Train Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")

# Accuracy
plt.subplot(1,2,2)
plt.plot(train_accuracies, label = "Train Acc", marker = 'o')
plt.plot(test_accuracies, label = "Test Acc",  marker = 'o')
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.tight_layout()
plt.show()

# t-SNE / UMAP 시각화
tsne = TSNE(n_components = 2, perplexity = 10, random_state = 42)
tsne_result = tsne.fit_transform(embeddings)

umap_model = umap.UMAP(n_components = 2, n_neighbors = 15, min_dist = 0.1, random_state = 42)
umap_result = umap_model.fit_transform(embeddings)

def plot_2d(data, labels, title):
  plt.figure(figsie = (8,6))
  scatter = plt.scatter(data[:,0], data[:,1], c=labels, cmap = 'tab10', alpha=0.7)
  plt.title(title)
  plt.colorbar(scatter)
  plt.show()

plot_2d(tsne_result, labels, "t-SNE Visualization")
plot_2d(umap_result, labels, "UMAP Visualization")